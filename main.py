import re as r;from thefuzz import fuzz as f;from nltk.tokenize import WordPunctTokenizer as t;from string import punctuation as p;u="utf-8";m=open;s=r.sub
with m("i",'r',-1,u)as i,m("o",'w',-1,u)as o:[[[o.write(' '+max([[c,f.ratio(w,c)]for c in[w.strip()for w in m("d",'r',-1,u)]],key=lambda x:x[1])[0])if w not in set(p)else o.write(w)for w in t().tokenize(s(r"\S?/\S?",'',s(r'\.\w','.',v)))],o.write('\n')] for v in i.readlines()]